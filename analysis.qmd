---
title: Analysis
description: Here we provide a detailed analysis using more sophisticated statistics techniques.
toc: true
draft: false
---
-   Introduce what motivates your Data Analysis (DA)
    -   Which variables and relationships are you most interested in?
    -   What questions are you interested in answering?
    
## Introduction
Our data analysis seeks to achieve an understanding of how and why H1-B applications vary across countries, continents, and time. We are interested in the number of applications from each country and/or continent, the wages of the recipients, the level of education that the applicants have achieved, and the financial information from their country of citizenship. We are interested in answering how the distribution of H1-B applicants has changed throughout time, whether education level and wage are correlated, and how that has changed, as well as whether the financial standing of a country is correlated with the number of citizens applying for an H1-B visa.

-   Modeling and Inference
    -   The page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.
    -   Explain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)
The following libraries will be used for analysis:
```{r}
#| code-fold: true
#| code-summary: "Libraries"
#| echo: false
suppressMessages(library(dplyr))
suppressMessages(library(tibble))
suppressMessages(library(tidyr))
suppressMessages(library(readxl))
suppressMessages(library(stringr))
suppressMessages(library(corrplot))
suppressMessages(library(ggplot2))
suppressMessages(library(car))
suppressMessages(library(caret))
suppressMessages(library(fastDummies))
```

First, the Perm Disclosure datasets for 2023 and 2024 are joined with IMF GDP and Unemployment rates by country. Thee education level of an applicant is made into a categorical variable, and the correlation between variables can be represented in the following correlation matrix.


```{r}
#| code-fold: true
#| code-summary: "[Correlation Matrix Code Block]"

data_for_heatmap <- read.csv('dataset/data_for_heatmap.csv')
cor_matrix <- cor(data_for_heatmap)
corrplot(cor_matrix, method = "color", type = "upper", order = "hclust",
         tl.col = "black", tl.srt = 45, title = "Correlation Heatmap", addCoef.col = "black", number.cex=0.8)
```

With the information from this correlation matrix, an initial linear regression model of Wage ~ GDP per Capita + Unemployment can be built. This linear model has the following statistics:

Residual standard error: 72550 on 14964 degrees of freedom
Multiple R-squared:  0.09498,	Adjusted R-squared:  0.09449 
F-statistic: 196.3 on 8 and 14964 DF,  p-value: < 2.2e-16

The Residual standard error indicates that the information provided by the GDP per capita and Unemployment of a country can predict the average wage of an H1-B recipient from that country with an average error of $72,550. A Mutliple R-squared of 0.09498 suggests that about 9.5% of the variability in the wage of H1-B recipients from a country can be explained by the GDP and Unemployment of that country.
Despite the fact that these values show that there is a lot of variability in wages not explained by the model, a p-value less than 0.05 leads to the conclusion that the model is statistically significant.

By plotting the diagnostics, a clear outlier that is affecting the strength of the model:


```{r}
#| code-fold: true
#| code-summary: "[Linear Model Diagnostics Code Block]"
h1b_final <- read.csv('dataset/h1b_final_lm.csv')
model_full <- lm(Wage ~ GDP.per.capita + Unemployment + None + High.School + Associate.s + Bachelor.s + Master.s + Doctorate, data = h1b_final)
vif(model_full)
par(mfrow = c(2, 2))
plot(model_full)
```

Using Cook's Distance, it can be seen that this outlier represents Nigeria, which has an average H1-B applicant wage of $6,524,999, a GDP of 1945.012,	and an unemployment rate of 22.6.

After removing this outlier, the dataset is split 90/10 into training and test sets, and the same linear regression model is built on the training set.
The model's predictive performance of the testing set has a RSME of 48892.1392815258 and Multiple R-squared of 0.1771, which shows significant improvement from the RSME of the previous model.

```{r}
#| code-fold: true
#| code-summary: "[Removing Outlier & Building Train/Test Model Code Block]"

# Removes outlier using Cook's Distance
cooks_distances <- cooks.distance(model_full)
threshold <- 0.5 # OR: 4 / (nrow(h1b_final) - length(coef(model)) - 1)
outliers <- which(cooks_distances > threshold)
h1b_final_no_outlier <- h1b_final[-outliers, ]
h1b_final[outliers, ]

# Splits data into train and test sets, using random seed
set.seed(123) 
training_rows <- createDataPartition(h1b_final_no_outlier$Wage, p = 0.9, list = FALSE)
train_data <- h1b_final_no_outlier[training_rows, ]
test_data <- h1b_final_no_outlier[-training_rows, ]

#Repeat previous model on training set only
model_train <- lm(Wage ~ GDP.per.capita + Unemployment + None + High.School + Associate.s + Bachelor.s + Master.s + Doctorate, data = train_data)

#Visualizing Actual vs Predicted
predictions <- predict(model_train, newdata = test_data)
test_data$Predicted_Wage <- predictions
ggplot(test_data, aes(x = Wage, y = Predicted_Wage)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(title = "Actual vs Predicted Wages", x = "Actual Wage", y = "Predicted Wage")
```

    -   Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.
Ultimately, 
    
## Modeling and Inference


This comes from the file `analysis.qmd`.

We describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You'll also reflect on next steps and further analysis.

The audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.

While the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.

The style of this paper should aim to be that of an academic paper. I don't expect this to be of publication quality but you should keep that aim in mind. Avoid using "we" too frequently, for example "We also found that ...". Describe your methodology and your findings but don't describe your whole process.

## Note on Attribution

In general, you should try to provide links to relevant resources, especially those that helped you. You don't have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don't need a formal citation.

If you are directly quoting from a source, please make that clear. You can show quotes using `>` like this

```         
> To be or not to be.
```

> To be or not to be.

------------------------------------------------------------------------

## Rubric: On this page

You will

-   Introduce what motivates your Data Analysis (DA)
    -   Which variables and relationships are you most interested in?
    -   What questions are you interested in answering?
    -   Provide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.
-   Modeling and Inference
    -   The page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.
    -   Explain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)
    -   Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.
-   Explain the flaws and limitations of your analysis
    -   Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?
-   Clarity Figures
    -   Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?
    -   Each figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)
    -   Default `lm` output and plots are typically not acceptable.
-   Clarity of Explanations
    -   How well do you explain each figure/result?
    -   Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?
-   Organization and cleanliness.
    -   Make sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.
    -   This page should be self-contained, i.e. provide a description of the relevant data.

# Motivation for Data Analysis

#### Table of Content

1.  Linear Modeling

2.  Forecasting number of H1B applications

# Linear Models

# Time Series Forcasting

![Total number of H1B applications in 2020-2024](images/applications.png)

The graph illustrates the total number of H1B applications from 2020 to 2024, providing valuable insights for prospective H1B applicants regarding near-future trends.

To project the volume of H1B applications for the year 2025, Prophet time series model was used. This approach was chosen due to its effectiveness in capturing data with inherent seasonality, which is common in industries where companies often undergo significant hiring cycles, typically peaking in the fall when budget allocations are highest. ![Total number of H1B applications in 2020-2024](images/total_cases.png)

### Interpretation

The forecast plot reveals promising prospects for prospective applicants, indicating the potential for a surge in hiring activities. The shaded regions delineate the upper and lower bounds of the forecast, offering a range within which the actual number of applications may fall.

This forecast holds significant implications for potential H1B applicants. Understanding these anticipated trends can inform strategic decision-making processes, ensuring proactive measures are taken to address potential challenges or capitalize on emerging opportunities.

#### Limitation

1.  The Prophet time series model is well-suited to analyze this dataset as it focuses on univariate time series data. However, it's worth noting that the model may not effectively account for multiple correlated time series.

2.  The year 2021 stands out as an outlier due to the unprecedented impact of the COVID-19. This global event significantly disrupted normal hiring patterns and economic activity, influencing the performance of forecasting models.

**Reference to Meta's algorithm**

https://facebook.github.io/prophet/
