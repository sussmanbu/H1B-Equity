---
title: "blogpost5"
description:  |
  This blog post will build on blogpost4 to merge the 3rd dataset by case
  numbers
author: "team3"
date: "2024-04-10"
date-modified: "2024-04-10"
draft: FALSE
---

```{r}
library(readxl)
library(readr)
library(dplyr)
```

```{r}
df <- readRDS("dataset/cleaned_disclosure.rds")
print(df)
```
# Combining Dataset

We selected this dataset, updated in 2024, because it comprehensively represents the evolution of U.S. immigration policy from the Trump to the Biden administration. It provides a wealth of columns suitable for statistical modeling. To enrich our analysis, we plan to merge it with two other datasets. The first includes information on the applicants' universities and majors, while the second contains data on their incomes, allowing us to construct a linear regression model. Once merged, we will have a dataframe with approximately 30+ columns.

This is the line of code of how to read xlsx files and convert into rds. We commented out after done
```{r}

# rds for the other two projects
# df2 <- read_excel("dataset/worksite.xlsx")
# saveRDS(df2, "dataset/LCA_worksite.rds")

# df3 <- read_excel("dataset/appendix.xlsx")
# saveRDS(df3, "dataset/LCA_appendix.rds")
```

```{r}
# read in df2

df2 <- readRDS("dataset/LCA_worksite.rds")

print(df2)
```

```{r}
# read in df3

df3 <- readRDS("dataset/appendix.rds")

print(df3)
```

## Merging Process
To merge the dataset together, we can find matching case numbers.

```{r}
# merge df1 and df2 by case number
# merge_1 <- merge(df, df2, by="CASE_NUMBER", all = TRUE)
```

```{r}
# final_merge <- merge(merge_1, df3, by="CASE_NUMBER", all = TRUE)
```

```{r}
# visualize our new dataset
# final_merge
```

```{r}
# save as new rds for final_merge
# saveRDS(final_merge, "dataset/final_merge.rds")
```

# Data Background
This is the dataset we are combining..
How are you combining them

# Start HERE - Import Data
```{r}
# just load in this dataset
final_df <- readRDS("dataset/final_merge.rds")
print(final_df)
```
# Exploration Data Analysis

```{r}
colnames(final_df)
```


```{r}
# let's check missing values
print(colSums(is.na(final_df)))
```
```{r}
unique(final_df["FULL_TIME_POSITION"])
```

### Employment Trends
What are some most common jobs titles, industries, or the duration of employment contracts.

```{r}
# filter the dataset which jobs have most frequency and applicant get full time position
filtered_data <- final_df |>
  filter(FULL_TIME_POSITION == "Y") |>
  count(JOB_TITLE, sort = TRUE)

print(filtered_data)
```
This is the most frequent job titles appear in the dataset. From this result, we can see that tech related jobs are still the highest percentage of applying for Visas.


```{r}
# filter the dataset which jobs have most frequency and applicant get full time position
filtered_data <- final_df |>
  count(EMPLOYER_NAME, sort = TRUE)

print(filtered_data)
```


### Geographical Patterns
In blog-post-4, we learned that New York and Massachusetts have a negative likelihood of getting fulltime position, perhaps we can investigate more here.

```{r}

# filter the dataset which jobs have most frequency and applicant get full time position
filtered_data <- final_df |>
  count(EMPLOYER_NAME, sort = TRUE)

print(filtered_data)
```

case status 
```{r}
case_df <- final_df %>%
  count(CASE_STATUS) %>%
  mutate(percent = n / sum(n) * 100)

ggplot(case_df, aes(x = CASE_STATUS, y = percent, fill = CASE_STATUS)) +
  geom_col() +
  geom_text(aes(label = sprintf("%.1f%%", percent)), position = position_stack(vjust = 0.5), hjust = 1) +
  labs(fill = "Case Status", title = "Distribution of CASE_STATUS")
```

```{r}

mydata=PERM_Disclosure_Data_FY2018_EOY
# Set seed for reproducibility
set.seed(123)

# Sample 1% of the data
mydata <- mydata[sample(nrow(mydata), size = 0.01 * nrow(mydata)), ]

status_counts <- mydata %>% count(CASE_STATUS)
ggplot(status_counts, aes(x = "", y = n, fill = CASE_STATUS)) +
    geom_bar(width = 1, stat = "identity") +
    coord_polar(theta = "y") +
    theme_void() +
    labs(fill = "Case Status", title = "Distribution of CASE_STATUS")
```
```{r}

lm_result <- lm(data_dif ~ PW_AMOUNT_9089, data = mydata)
summary(lm_result)

```


### Linear Regression
This time with numerical columns(wage), we can predict wages based on various features

=======
### Clustering Analysis
We can make use of various clustering techniques to group similar applicants together.
```{r}
library(tidymodels)
library(cluster)
library(ggplot2)
library(dplyr)

filtered_df <- final_df %>%
  # filter(JOB_TITLE %in% c("Software Engineer", "Assistant Professor", "Business Analyst", "Machine Learning Engineer"),
  # FULL_TIME_POSITION %in% c("Y", "N")) %>%
  select(WAGE_RATE_OF_PAY_FROM, PREVAILING_WAGE)

print(filtered_df)
```


```{r}
# create recipe
rec <- recipe(~ ., data=filtered_df) |>
  step_dummy(all_nominal()) |>
  prep()

cluster_data <- bake(rec, new_data=NULL)

# perform clustering
set.seed(42)
k <- 5
clustered_result <- kmeans(cluster_data, centers=k)

# visualize cluster
filtered_df$cluster <- factor(clustered_result$cluster)
print(filtered_df)
```

```{r}
library(ggplot2)

ggplot(filtered_df, aes(x = WAGE_RATE_OF_PAY_FROM, y = PREVAILING_WAGE)) +
  geom_point(aes(color = cluster)) +
  # facet_wrap(~ cluster) +
  theme_minimal() +
  labs(title = "Wage Rate vs. Prevailing Wage by Cluster") +
  scale_x_log10() +
  scale_y_log10()
  
```

# Observation and Limitation

WAGE_RATE_OF_PAY_FROM is the minimum wage pay at the worksite, 

PREVAILING_WAGE is the average wage paid to similar employed workers in the field

Looking at the result of KMeans with only two numerical columns, it was not necessary to make use of Kmeans because is obvious to notice a linear relationship. There's a positive correlation between these two features. It is expected that employers are pay more at the worksite than prevailng wages.

For example, applicants who are highly specialized / high demand positions mostly lie in cluster 4. 

To recall, one limitation of this KMeans is the choice of cluster, k, and limited numerical columns to work with. 
# What's Next

### Build on Logistic Regression
This time with more features/columns, we can build a better logistic regression model to predict approved or denial

### Linear Regression on income
