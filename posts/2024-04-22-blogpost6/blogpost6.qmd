---
title: "blogpost6"
author: ""
date: "2024-04-22"
date-modified: "2024-04-22"
draft: FALSE
---

## Import library
```{r}
suppressPackageStartupMessages(library(tidyverse))
library(tidyr)
library(viridis)
library(ggplot2)
library(dplyr)
library(ggfortify)
library(tidymodels)
library(readxl)
library(readr)
library(lubridate)
```

```{r}
final_df <- readRDS("dataset/final_merge.rds")
head(final_df)
```

```{r}
perm_df <- readRDS("dataset/perm_data.rds")
head(perm_df)
```

```{r}
final_perm_df <- select(perm_df, "CASE_NUMBER", "CASE_STATUS", "RECEIVED_DATE", "DECISION_DATE", "EMPLOYER_NAME",
                        "EMPLOYER_NUM_EMPLOYEES", "AGENT_ATTORNEY_FIRM_NAME", "PW_WAGE", "PW_SKILL_LEVEL", "WORKSITE_STATE", "JOB_TITLE", "PW_UNIT_OF_PAY", "WAGE_OFFER_FROM", "WAGE_OFFER_UNIT_OF_PAY",
                        , "MINIMUM_EDUCATION", "REQUIRED_EXPERIENCE", "COUNTRY_OF_CITIZENSHIP", "CLASS_OF_ADMISSION"
                        )

final_perm_df <- final_perm_df %>%
  filter(PW_UNIT_OF_PAY == "Year")
final_perm_df
```
```{r}
country_df <- final_perm_df |>
  group_by(COUNTRY_OF_CITIZENSHIP) |>
  summarise(
    total_country = n(),
    Approved_Applications = sum(CASE_STATUS == "Certified")
  )

# Sort by total country
country_data_sorted_applicants <- country_df %>%
  arrange(desc(total_country))

top_country <- country_data_sorted_applicants |>
  top_n(10, total_country)

# visualizing
# Plot for Total country
ggplot(top_country, aes(x = reorder(COUNTRY_OF_CITIZENSHIP, -total_country), y = total_country)) +
  geom_bar(stat = "identity") +
  theme(axis.text.y = element_text(size = 6)) +  # Smaller text size for states
  labs(title = "Total number of certified Applications", x = "Country Origin", y = "Number of certified cases") +
  coord_flip()  # Flips the coordinates to make labels readable
```
we see a same relationship from dataset2, we have majority of the H1B workers coming from the following country. India is the top population of H1B worker.



```{r}
# loading merge_df to visualize number applications vs years
final_df <- readRDS("dataset/final_merge.rds")

final_df$YEAR_BEGIN = as.integer(substr(final_df$BEGIN_DATE, 1, 4))
final_df$MONTH_BEGIN = month(final_df$BEGIN_DATE)
final_df$DAY_BEGIN = day(final_df$BEGIN_DATE)

```

```{r}
summary_data <- final_df |>
  group_by(YEAR_BEGIN, MONTH_BEGIN) |>
  summarise(total_cases = n_distinct(CASE_NUMBER))

# Creating a new combined column for plotting
summary_data$YearMonth <- as.Date(paste(summary_data$YEAR_BEGIN, summary_data$MONTH_BEGIN, "01", sep="-"))


# Plotting the data
ggplot(summary_data, aes(x = YearMonth, y = log(total_cases) )) +
  geom_line() +  # Use geom_line() for line plot
  geom_point() + # Adding points to the line plot
  scale_x_date(date_breaks = "3 months", date_labels = "%Y-%m") +
  labs(title = "Total Log-Scale Cases Per Year in US",
       x = "Year",
       y = "Total Log Distinct Cases") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
This plot is showing employees actually getting hired and start employment.
For instance, 2024-07 is into the future and it means: the beginning date of period of employment.

It might be interesting to explore policies or recall a news called massive hire during covid period. 2022 - 2023.


```{r}
# Split data into training and testing sets
set.seed(123)
data_split <- initial_split(final_perm_df, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Create a recipe for preprocessing
recipe <- recipe(WAGE_OFFER_FROM ~ WORKSITE_STATE + PW_SKILL_LEVEL + MINIMUM_EDUCATION + REQUIRED_EXPERIENCE, data = train_data) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_predictors())

# Create a model specification
model_spec <- linear_reg() %>% 
  set_engine("lm") %>% 
  set_mode("regression")

# Bundle the recipe and model spec in a workflow
workflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(model_spec)

# Fit the model
fitted_model <- fit(workflow, data = train_data)

# Evaluate the model
test_results <- fitted_model %>%
  predict(new_data = test_data) %>%
  bind_cols(test_data) %>%
  metrics(truth = WAGE_OFFER_FROM, estimate = .pred)

# Print results
print(test_results)
```
```{r}
# Extract the model fit and view the summary
model_fit <- extract_fit_parsnip(fitted_model)
summary(model_fit$fit)
```

## Residual Analysis
```{r}
# Predict and calculate residuals
residuals_df <- fitted_model %>%
  predict(new_data = test_data) %>%
  bind_cols(test_data) %>%
  mutate(residuals = WAGE_OFFER_FROM - .pred)

# Plot residuals
ggplot(residuals_df, aes(x = .pred, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(x = "Predicted", y = "Residuals", title = "Residual Plot")
```

## variable analysis
```{r}
# Extract model coefficients and sort by absolute value
importance <- tidy(model_fit$fit) %>%
  filter(term != "(Intercept)") %>%
  arrange(desc(abs(estimate)))

print(importance)
```

```{r}
# Plot diagnostic plots
autoplot(model_fit$fit)
```

```{r}
# Set up cross-validation
cv_folds <- vfold_cv(train_data, v = 5)

# Fit and evaluate the model across folds
cv_results <- fit_resamples(
  workflow,
  resamples = cv_folds,
  metrics = metric_set(rmse, rsq)
)
collect_metrics(cv_results)
```

```{r}
# Calculate and add prediction intervals to the prediction frame
interval_df <- predict(fitted_model, new_data = test_data, type = "pred_int", level = 0.95)
# print(interval_df)

print(test_data)
```


# Conclusion
Based on the dataset, linear regression(multivariate) is not feasible in this dataset. In terms of next step,
As you can see at the feature space, the data might need a model that can capture nonlinear relationships. Neural network is a bit overkill but other machine learning models such as random forest, XGBOOST, and support vector machine can help explain the dataset.