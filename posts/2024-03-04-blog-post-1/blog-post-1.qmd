
---
title: "Blog Post 1"
author: "T3am-3"
subtitle: ""
description:  |
  This post details our choices for dataset
date: "2024-03-04"
date-modified: "2024-03-04"
draft: FALSE
---

1. The first dataset we looked at is from the US Citizenship and Immigration Services (USCIS) website: https://www.uscis.gov/tools/reports-and-studies/h-1b-employer-data-hub/h-1b-employer-data-hub-files

It contains 15 csv files ranging from years 2009 to 2023 with about 30,000 rows per csv file and 10 columns including the fiscal year.
Looking at the columns of this dataset, it seems it was collected to see how many H1B goes through each year with number of denials, tax id, and the city applicants in. Because this is a tabular dataset, it is possible to load in R easily and start exploration data analysis.
One challenge of working with dataset is the fact that it might not help us answer deep questions. For example, if we want to answer questions such as what companies, salary incomes(plotting salary distributions versus other features), ethnicity groups, and gender.

Note: This same dataset can be found from U.S citizenship immigration services, but someone uploaded to Kaggle.

2. The second dataset[s] we will analyze is from travel.state.gov and can be found at: [travel.state.gov](https://travel.state.gov/content/travel/en/legal/visa-law0/visa-statistics/annual-reports.html)

The data includes rows of countries of origin, separated by continent. The columns include Visa type and total visas issued. There is data that includes the month of the issuance as well. 

This data was published by the Visa Office of the US on the [travel.state.gov](http://travel.state.gov) website. The main question this dataset addresses is the country of origin of visa recipients.

We will load the data by using optical character recognition and combine the datasets from each year to form one large dataset. This larger dataset will have multiple rows for each country, one for each year from 2000-2023(maybe month as well) and can be used to evaluate changes in issuances by country over time.

It may be challenging to load the data because it could be tedious. Also, this data will be difficult to join with other datasets because the most ‘relevant’ joining column will be month/year of issuance, which is not a very specific identifier for this data.

3. The last dataset we plan to use is from the US Department of Labor: https://www.dol.gov/agencies/eta/foreign-labor/performance 

It contains detailed performance data on H-1B applications from 2008 to 2023, with approximately 600,000 to 630,000 rows per CSV file and 26 columns. Each row represents one H-1B applicant with their case number. The 26 columns include information such as applicants’ job titles, application dates, wage levels, postal codes, etc. This data was published by the US Department of Labor. We will load the data in R, as all the data are saved in CSV files and organized by year. This dataset contains very precise information, and we want to focus on the applicants’ job titles, wage levels, and their postal codes to find out the economic impact of H-1B visas. One possible challenge I notice is that the dataset contains a huge amount of data; it’s important for us to filter out irrelevant information.

